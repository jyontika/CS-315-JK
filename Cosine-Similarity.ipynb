{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity Notebook \n",
    "\n",
    "#### @Author: Jyontika Kapoor\n",
    "\n",
    "\n",
    "#### **Steps:**\n",
    "Step 1: Create the vocabulary of all unique terms (each of them will be a dimension) \n",
    "\n",
    "Step 2: Represent each document and the query in the vector space created by these terms\n",
    "\n",
    "Step 3: Calculate the cosine similarity between the query and each document\n",
    "\n",
    "Step 4: Rank the results based on the cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/hzlwrw5d571cgm5snsf618b00000gn/T/ipykernel_64551/1662815981.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_vocabulary(document_text):\n",
    "    \"\"\"\n",
    "    Step 1: Create the vocabulary of all unique terms (each of them will be a dimension)\n",
    "    \n",
    "    @param: document_text is an input  text for vocabulary creation\n",
    "    \"\"\"\n",
    "    document_text = document_text.lower()\n",
    "    text = \"\".join(char for char in document_text if char not in string.punctuation)\n",
    "    words = set(text.split())\n",
    "    vocabulary = sorted(words)\n",
    "\n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "def test_create_vocabulary():\n",
    "    # Test Case 1: Basic functionality\n",
    "    text_1 = \"This is a simple test.\"\n",
    "    result_1 = create_vocabulary(text_1)\n",
    "    assert result_1 == ['a', 'is', 'simple', 'test', 'this']\n",
    "\n",
    "    # Test Case 2: Empty input\n",
    "    text_2 = \"\"\n",
    "    result_2 = create_vocabulary(text_2)\n",
    "    assert result_2 == []\n",
    "\n",
    "    # Test Case 3: Input with punctuation\n",
    "    text_3 = \"Python is awesome!\"\n",
    "    result_3 = create_vocabulary(text_3)\n",
    "    assert result_3 == ['awesome', 'is', 'python']\n",
    "\n",
    "    # Test Case 4: Input with repeated words\n",
    "    text_4 = \"Testing testing one two two\"\n",
    "    result_4 = create_vocabulary(text_4)\n",
    "    assert result_4 == ['one', 'testing', 'two']\n",
    "\n",
    "    print(\"All test cases passed!\")\n",
    "\n",
    "# Run test cases\n",
    "test_create_vocabulary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Step 2: Represent each document and the query in the vector space created by these terms\n",
    "\n",
    "def sentence_to_vector(sentence, vocabulary):\n",
    "    \"\"\"Represents each sentence as a vector\"\"\"\n",
    "    sentence_vector = [sentence.lower().split().count(word) for word in vocabulary]\n",
    "    return sentence_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 Vector: [0, 1, 0, 1, 0, 0, 0, 1, 0, 1]\n",
      "Sentence 2 Vector: [0, 0, 0, 1, 0, 1, 1, 1, 0, 0]\n",
      "Sentence 3 Vector: [1, 0, 0, 1, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "        \"This is the first sentence.\",\n",
    "        \"The second sentence is here.\",\n",
    "        \"And this is the third one.\",\n",
    "    ]\n",
    "\n",
    "\n",
    "all_text = \" \".join(sentences)\n",
    "vocab = create_vocabulary(all_text)\n",
    "\n",
    "# Convert each sentence to a vector\n",
    "sentence_vectors = [sentence_to_vector(sentence, vocab) for sentence in sentences]\n",
    "\n",
    "\n",
    "for i, vector in enumerate(sentence_vectors, 1):\n",
    "        print(f\"Sentence {i} Vector: {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: calculate cosine similarity  between query and each document\n",
    "\n",
    "def calculate_cosine_similarity(query_vector, document_vector):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between a query vector and a document vector.\n",
    "    \"\"\"\n",
    "    #  dot product\n",
    "    dot_product = sum(i * j for i, j in zip(query_vector, document_vector))\n",
    "\n",
    "    #  magnitudes\n",
    "    query_magnitude = sum(i**2 for i in query_vector) ** 0.5\n",
    "    document_magnitude = sum(i**2 for i in document_vector) ** 0.5\n",
    "\n",
    "    #  cosine similarity\n",
    "    if query_magnitude == 0 or document_magnitude == 0:\n",
    "        return 0  # if 1 or both vectors are 0 vectors\n",
    "    else:\n",
    "        similarity = dot_product / (query_magnitude * document_magnitude)\n",
    "        return similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.4999999999999999\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "query_vector = [1, 0, 1]\n",
    "document_vector = [0, 1, 1]\n",
    "\n",
    "cosine_similarity_value = calculate_cosine_similarity(query_vector, document_vector)\n",
    "print(f\"Cosine Similarity: {cosine_similarity_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: rank documents\n",
    "\n",
    "def rank_results(query_vector, document_vectors):\n",
    "    \"\"\"\n",
    "    Rank the results based on cosine similarity between the query and each document.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i, document_vector in enumerate(document_vectors):\n",
    "        similarity = calculate_cosine_similarity(query_vector, document_vector)\n",
    "        results.append((i, similarity))\n",
    "\n",
    "    # Rank results based on cosine similarity\n",
    "    ranked_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    return ranked_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Document 3 - Cosine Similarity: 0.7071067811865475\n",
      "Rank 2: Document 1 - Cosine Similarity: 0.4999999999999999\n",
      "Rank 3: Document 2 - Cosine Similarity: 0.4999999999999999\n"
     ]
    }
   ],
   "source": [
    "# tests\n",
    "query_vector = [1, 0, 1]\n",
    "document_vectors = [[0, 1, 1], [1, 1, 0], [0, 0, 1]]\n",
    "\n",
    "ranked_results = rank_results(query_vector, document_vectors)\n",
    "\n",
    "for rank, (doc_index, similarity) in enumerate(ranked_results, 1):\n",
    "    print(f\"Rank {rank}: Document {doc_index + 1} - Cosine Similarity: {similarity}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
